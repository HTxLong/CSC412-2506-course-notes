



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
        <link rel="canonical" href="https://johngiorgi.github.io/CSC412-2506-course-notes/. /lectures/week_10/">
      
      
        <meta name="author" content="John Giorgi">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-3.2.0">
    
    
      
        <title>Week 10 - CSC412/2506 Winter 2019: Probabilistic Learning and Reasoning</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.572ca0f0.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/application-palette.22915126.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
      <script src="../../assets/javascripts/modernizr.8c900955.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../../styles/extra.css">
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#week-10-stochastic-variational-inference-automatic-differentiation-variation-inference-sad-vi" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://johngiorgi.github.io/CSC412-2506-course-notes/. " title="CSC412/2506 Winter 2019: Probabilistic Learning and Reasoning" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                CSC412/2506 Winter 2019: Probabilistic Learning and Reasoning
              </span>
              <span class="md-header-nav__topic">
                Week 10
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/JohnGiorgi/CSC412-2506-course-notes/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      JohnGiorgi/CSC412-2506-course-notes
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://johngiorgi.github.io/CSC412-2506-course-notes/. " title="CSC412/2506 Winter 2019: Probabilistic Learning and Reasoning" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    CSC412/2506 Winter 2019: Probabilistic Learning and Reasoning
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/JohnGiorgi/CSC412-2506-course-notes/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      JohnGiorgi/CSC412-2506-course-notes
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="About" class="md-nav__link">
      About
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      Lectures
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Lectures
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../week_1/" title="Week 1" class="md-nav__link">
      Week 1
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week_2/" title="Week 2" class="md-nav__link">
      Week 2
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week_3/" title="Week 3" class="md-nav__link">
      Week 3
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week_4/" title="Week 4" class="md-nav__link">
      Week 4
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week_5/" title="Week 5" class="md-nav__link">
      Week 5
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week_6/" title="Week 6" class="md-nav__link">
      Week 6
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week_8/" title="Week 8" class="md-nav__link">
      Week 8
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week_9/" title="Week 9" class="md-nav__link">
      Week 9
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Week 10
      </label>
    
    <a href="./" title="Week 10" class="md-nav__link md-nav__link--active">
      Week 10
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#assigned-reading" title="Assigned Reading" class="md-nav__link">
    Assigned Reading
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#overview" title="Overview" class="md-nav__link">
    Overview
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#posterior-inference-for-latent-variable-models" title="Posterior Inference for Latent Variable Models" class="md-nav__link">
    Posterior Inference for Latent Variable Models
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#approximating-the-posterior-inference-with-variational-methods" title="Approximating the Posterior Inference with Variational Methods" class="md-nav__link">
    Approximating the Posterior Inference with Variational Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kullback-leibler-divergence" title="Kullback-Leibler Divergence" class="md-nav__link">
    Kullback-Leibler Divergence
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#properties-of-the-kl-divergence" title="Properties of the KL Divergence" class="md-nav__link">
    Properties of the KL Divergence
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variational-objective" title="Variational Objective" class="md-nav__link">
    Variational Objective
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#alternative-derivation" title="Alternative Derivation" class="md-nav__link">
    Alternative Derivation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alternative-forms-of-elbo-and-intuitions" title="Alternative Forms of ELBO and Intuitions" class="md-nav__link">
    Alternative Forms of ELBO and Intuitions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-field-variational-inference" title="Mean Field Variational Inference" class="md-nav__link">
    Mean Field Variational Inference
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#appendix" title="Appendix" class="md-nav__link">
    Appendix
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#useful-resources" title="Useful Resources" class="md-nav__link">
    Useful Resources
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#glossary-of-terms" title="Glossary of Terms" class="md-nav__link">
    Glossary of Terms
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week_11/" title="Week 11" class="md-nav__link">
      Week 11
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week_12.md" title="Week 12" class="md-nav__link">
      Week 12
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../week_13.md" title="Week 13" class="md-nav__link">
      Week 13
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Tutorials
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Tutorials
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../tutorials/week_1/" title="Week 1" class="md-nav__link">
      Week 1
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../sample_midterm/" title="Sample Midterm" class="md-nav__link">
      Sample Midterm
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../sample_final/" title="Sample Final" class="md-nav__link">
      Sample Final
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#assigned-reading" title="Assigned Reading" class="md-nav__link">
    Assigned Reading
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#overview" title="Overview" class="md-nav__link">
    Overview
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#posterior-inference-for-latent-variable-models" title="Posterior Inference for Latent Variable Models" class="md-nav__link">
    Posterior Inference for Latent Variable Models
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#approximating-the-posterior-inference-with-variational-methods" title="Approximating the Posterior Inference with Variational Methods" class="md-nav__link">
    Approximating the Posterior Inference with Variational Methods
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kullback-leibler-divergence" title="Kullback-Leibler Divergence" class="md-nav__link">
    Kullback-Leibler Divergence
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#properties-of-the-kl-divergence" title="Properties of the KL Divergence" class="md-nav__link">
    Properties of the KL Divergence
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variational-objective" title="Variational Objective" class="md-nav__link">
    Variational Objective
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#alternative-derivation" title="Alternative Derivation" class="md-nav__link">
    Alternative Derivation
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#alternative-forms-of-elbo-and-intuitions" title="Alternative Forms of ELBO and Intuitions" class="md-nav__link">
    Alternative Forms of ELBO and Intuitions
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-field-variational-inference" title="Mean Field Variational Inference" class="md-nav__link">
    Mean Field Variational Inference
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#appendix" title="Appendix" class="md-nav__link">
    Appendix
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#useful-resources" title="Useful Resources" class="md-nav__link">
    Useful Resources
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#glossary-of-terms" title="Glossary of Terms" class="md-nav__link">
    Glossary of Terms
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/JohnGiorgi/CSC412-2506-course-notes/edit/master/docs/lectures/week_10.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="week-10-stochastic-variational-inference-automatic-differentiation-variation-inference-sad-vi">Week 10:  Stochastic Variational Inference / Automatic Differentiation Variation Inference (SAD VI)<a class="headerlink" href="#week-10-stochastic-variational-inference-automatic-differentiation-variation-inference-sad-vi" title="Permanent link">&para;</a></h1>
<h3 id="assigned-reading">Assigned Reading<a class="headerlink" href="#assigned-reading" title="Permanent link">&para;</a></h3>
<ul>
<li>Murphy: Chapter 18</li>
</ul>
<h3 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link">&para;</a></h3>
<ul>
<li>Review Variational Inference</li>
<li>Derive the variational objective</li>
<li>ELBO intuition</li>
<li>Stochastic optimization</li>
</ul>
<h2 id="posterior-inference-for-latent-variable-models">Posterior Inference for Latent Variable Models<a class="headerlink" href="#posterior-inference-for-latent-variable-models" title="Permanent link">&para;</a></h2>
<p>Imagine we had the following latent variable model</p>
<p><img alt="" src="../../img/lecture_9_1.png" /></p>
<p>which represents the probabilistic model <span><span class="MathJax_Preview">p(x, z ; \theta)</span><script type="math/tex">p(x, z ; \theta)</script></span> where</p>
<ul>
<li><span><span class="MathJax_Preview">x_{1:N}</span><script type="math/tex">x_{1:N}</script></span> are the observations</li>
<li><span><span class="MathJax_Preview">z_{1:N}</span><script type="math/tex">z_{1:N}</script></span> are the unobserved local latent variables</li>
<li><span><span class="MathJax_Preview">\theta</span><script type="math/tex">\theta</script></span> are the global latent variables (i.e. the parameters)</li>
</ul>
<p>The conditional distribution of the unobserved variables given the observed variables (the posterior inference) is</p>
<div>
<div class="MathJax_Preview">
p(z, \theta | x) = \frac{p(x | z, \theta)}{p(x)} = \frac{p(x | z, \theta)}{\int\int p(x, z, \theta)d_zd_{\theta}}
</div>
<script type="math/tex; mode=display">
p(z, \theta | x) = \frac{p(x | z, \theta)}{p(x)} = \frac{p(x | z, \theta)}{\int\int p(x, z, \theta)d_zd_{\theta}}
</script>
</div>
<p>which we will denote as <span><span class="MathJax_Preview">p_{\theta}(z | x)</span><script type="math/tex">p_{\theta}(z | x)</script></span>.</p>
<p>Because the computation <span><span class="MathJax_Preview">\int\int p(x, z, \theta)d_zd_{\theta}</span><script type="math/tex">\int\int p(x, z, \theta)d_zd_{\theta}</script></span> is intractable, making the computation of the conditional distribution itself intractable, we must turn to variational methods.</p>
<h3 id="approximating-the-posterior-inference-with-variational-methods">Approximating the Posterior Inference with Variational Methods<a class="headerlink" href="#approximating-the-posterior-inference-with-variational-methods" title="Permanent link">&para;</a></h3>
<p>Approximation of the posterior inference with variational methods works as follows:</p>
<ol>
<li>Introduce a variational family, <span><span class="MathJax_Preview">q_\phi(z | x)</span><script type="math/tex">q_\phi(z | x)</script></span> with parameters <span><span class="MathJax_Preview">\phi</span><script type="math/tex">\phi</script></span>.</li>
<li>Encode some notion of "distance" between <span><span class="MathJax_Preview">p_\theta</span><script type="math/tex">p_\theta</script></span> and <span><span class="MathJax_Preview">q_\phi</span><script type="math/tex">q_\phi</script></span>.</li>
<li>Minimize this distance.</li>
</ol>
<p>This process effectively turns Bayesian Inference into an optimization problem (and we <em>love</em> optimization problems in machine learning).</p>
<p>It is important to note that whatever function we choose for <span><span class="MathJax_Preview">q_\phi</span><script type="math/tex">q_\phi</script></span>, it is unlikely that our variational family will have the true distribution <span><span class="MathJax_Preview">p_\theta</span><script type="math/tex">p_\theta</script></span> in it.</p>
<p><img alt="" src="../../img/lecture_9_2.png" /></p>
<h4 id="kullback-leibler-divergence">Kullback-Leibler Divergence<a class="headerlink" href="#kullback-leibler-divergence" title="Permanent link">&para;</a></h4>
<p>We will measure the distance between <span><span class="MathJax_Preview">q_\phi</span><script type="math/tex">q_\phi</script></span> and <span><span class="MathJax_Preview">p_\theta</span><script type="math/tex">p_\theta</script></span> using the <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence"><strong>Kullback-Leibler divergence</strong></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Kullback–Leibler divergence has lots of names, we will stick to <em>"KL divergence"</em>.</p>
</div>
<p>We compute <span><span class="MathJax_Preview">D_{KL}</span><script type="math/tex">D_{KL}</script></span> as follows:</p>
<div>
<div class="MathJax_Preview">\begin{align}
  D_{KL}(q_\phi(z | x) || p_\theta(z | x)) &amp;= \int q_\phi(z | x) \log \frac{q_\phi(z | x)}{p_\theta(z | x)}dz \\
  &amp;= E_{z_\phi \sim q_\phi} \log \frac{q_\phi(z | x)}{p_\theta(z | x)}
\end{align}</div>
<script type="math/tex; mode=display">\begin{align}
  D_{KL}(q_\phi(z | x) || p_\theta(z | x)) &= \int q_\phi(z | x) \log \frac{q_\phi(z | x)}{p_\theta(z | x)}dz \\
  &= E_{z_\phi \sim q_\phi} \log \frac{q_\phi(z | x)}{p_\theta(z | x)}
\end{align}</script>
</div>
<h5 id="properties-of-the-kl-divergence">Properties of the KL Divergence<a class="headerlink" href="#properties-of-the-kl-divergence" title="Permanent link">&para;</a></h5>
<ol>
<li><span><span class="MathJax_Preview">D_{KL}(q_\phi || p_\theta) \ge 0</span><script type="math/tex">D_{KL}(q_\phi || p_\theta) \ge 0</script></span></li>
<li><span><span class="MathJax_Preview">D_{KL}(q_\phi || p_\theta) = 0 \Leftrightarrow q_\phi = p_\theta</span><script type="math/tex">D_{KL}(q_\phi || p_\theta) = 0 \Leftrightarrow q_\phi = p_\theta</script></span></li>
<li><span><span class="MathJax_Preview">D_{KL}(q_\phi || p_\theta) \not = D_{KL}(p_\theta || q_\phi)</span><script type="math/tex">D_{KL}(q_\phi || p_\theta) \not = D_{KL}(p_\theta || q_\phi)</script></span></li>
</ol>
<p>The significance of the last property is that <span><span class="MathJax_Preview">D_{KL}</span><script type="math/tex">D_{KL}</script></span> is <em>not</em> a true distance measure.</p>
<h3 id="variational-objective">Variational Objective<a class="headerlink" href="#variational-objective" title="Permanent link">&para;</a></h3>
<p>We want to approximate <span><span class="MathJax_Preview">p_\theta</span><script type="math/tex">p_\theta</script></span> by finding a <span><span class="MathJax_Preview">q_\phi</span><script type="math/tex">q_\phi</script></span> such that</p>
<div>
<div class="MathJax_Preview">
q_\phi \approx p_\theta \Rightarrow D_{KL}(q_\phi || p_\theta) = 0
</div>
<script type="math/tex; mode=display">
q_\phi \approx p_\theta \Rightarrow D_{KL}(q_\phi || p_\theta) = 0
</script>
</div>
<p>but the computation of <span><span class="MathJax_Preview">D_{KL}(q_\phi || p_\theta)</span><script type="math/tex">D_{KL}(q_\phi || p_\theta)</script></span> is intractable (as discussed above).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><span><span class="MathJax_Preview">D_{KL}(q_\phi || p_\theta)</span><script type="math/tex">D_{KL}(q_\phi || p_\theta)</script></span> is intractable because it contains the term <span><span class="MathJax_Preview">p_\theta(z | x)</span><script type="math/tex">p_\theta(z | x)</script></span>, which we have already established, is intractable.</p>
</div>
<p>To circumvent this issue of intractability, we will derive the <a href="https://en.wikipedia.org/wiki/Evidence_lower_bound"><strong>evidence lower bound (ELBO)</strong></a>, and show that maximizing the ELBO <span><span class="MathJax_Preview">\Rightarrow</span><script type="math/tex">\Rightarrow</script></span> minimizing <span><span class="MathJax_Preview">D_{KL}(q_\phi || p_\theta)</span><script type="math/tex">D_{KL}(q_\phi || p_\theta)</script></span>.</p>
<div>
<div class="MathJax_Preview">\begin{align}
  D_{KL}(q_\phi || p_\theta) &amp;= E_{z_\phi \sim q_\phi} \log \frac{q_\phi(z | x)}{p_\theta(z | x)} \\
  &amp;= E_{z_\phi \sim q_\phi} \Bigg [ \log \Bigg ( q_\phi(z | x) \cdot \frac{p_\theta(x)}{p_\theta(z, x)} \Bigg ) \Bigg ] \\
  &amp;= E_{z_\phi \sim q_\phi} \log \frac{q_\phi(z | x)}{p_\theta(z, x)}  + E_{z_\phi \sim q_\phi} \log p_\theta(x) \\
  &amp;= -\mathcal L(\theta, \phi ; x)  + \log p_\theta(x) \\
\end{align}</div>
<script type="math/tex; mode=display">\begin{align}
  D_{KL}(q_\phi || p_\theta) &= E_{z_\phi \sim q_\phi} \log \frac{q_\phi(z | x)}{p_\theta(z | x)} \\
  &= E_{z_\phi \sim q_\phi} \Bigg [ \log \Bigg ( q_\phi(z | x) \cdot \frac{p_\theta(x)}{p_\theta(z, x)} \Bigg ) \Bigg ] \\
  &= E_{z_\phi \sim q_\phi} \log \frac{q_\phi(z | x)}{p_\theta(z, x)}  + E_{z_\phi \sim q_\phi} \log p_\theta(x) \\
  &= -\mathcal L(\theta, \phi ; x)  + \log p_\theta(x) \\
\end{align}</script>
</div>
<p>Where <span><span class="MathJax_Preview">\mathcal L(\theta, \phi ; x)</span><script type="math/tex">\mathcal L(\theta, \phi ; x)</script></span> is the <strong>ELBO</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Notice that <span><span class="MathJax_Preview">\log p_\theta(x)</span><script type="math/tex">\log p_\theta(x)</script></span> is <em>not</em> dependent on <span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>.</p>
</div>
<p>Rearranging, we get</p>
<div>
<div class="MathJax_Preview">\begin{align}
  D_{KL}(q_\phi || p_\theta) &amp;= -\mathcal L(\theta, \phi ; x)  + \log p_\theta(x) \\
  \Rightarrow \mathcal L(\theta, \phi ; x) + D_{KL}(q_\phi || p_\theta) &amp;= \log p_\theta(x) \\
\end{align}</div>
<script type="math/tex; mode=display">\begin{align}
  D_{KL}(q_\phi || p_\theta) &= -\mathcal L(\theta, \phi ; x)  + \log p_\theta(x) \\
  \Rightarrow \mathcal L(\theta, \phi ; x) + D_{KL}(q_\phi || p_\theta) &= \log p_\theta(x) \\
\end{align}</script>
</div>
<p>Because <span><span class="MathJax_Preview">D_{KL}(q_\phi || p_\theta) \ge 0</span><script type="math/tex">D_{KL}(q_\phi || p_\theta) \ge 0</script></span></p>
<div>
<div class="MathJax_Preview">
\mathcal L(\theta, \phi ; x) \le \log p_\theta(x)
</div>
<script type="math/tex; mode=display">
\mathcal L(\theta, \phi ; x) \le \log p_\theta(x)
</script>
</div>
<p><span><span class="MathJax_Preview">\therefore</span><script type="math/tex">\therefore</script></span> maximizing the ELBO <span><span class="MathJax_Preview">\Rightarrow</span><script type="math/tex">\Rightarrow</script></span> minimizing <span><span class="MathJax_Preview">D_{KL}(q_\phi || p_\theta)</span><script type="math/tex">D_{KL}(q_\phi || p_\theta)</script></span>.</p>
<h4 id="alternative-derivation">Alternative Derivation<a class="headerlink" href="#alternative-derivation" title="Permanent link">&para;</a></h4>
<p>Starting with <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality"><strong>Jenson's inequality</strong></a>,</p>
<div>
<div class="MathJax_Preview">
f(E[X]) \le E[f(x)]
</div>
<script type="math/tex; mode=display">
f(E[X]) \le E[f(x)]
</script>
</div>
<p>if <span><span class="MathJax_Preview">X</span><script type="math/tex">X</script></span> is a random variable and <span><span class="MathJax_Preview">f</span><script type="math/tex">f</script></span> is a convex function.</p>
<p>Given that <span><span class="MathJax_Preview">\log</span><script type="math/tex">\log</script></span> is a concave function, we have</p>
<div>
<div class="MathJax_Preview">\begin{align}
\log p(x) &amp;= \log \int p_\theta(x, z)dz \\
&amp;= \log \int p_\theta(x, z) \frac{q_\phi(z | x)}{q_\phi(z | x)} dz \\
&amp;= \log E_{z_\phi \sim q_\phi} \frac{p_\theta(x, z)}{q_\phi(z | x)} \\
\Rightarrow  \log E_{z_\phi \sim q_\phi} \frac{p_\theta(x, z)}{q_\phi(z | x)} &amp; \ge E_{z_\phi \sim q_\phi} \log \frac{p_\theta(x, z)}{q_\phi(z | x)} \\  
&amp;= - E_{z_\phi \sim q_\phi} \log \frac{q_\phi(z | x)}{p_\theta(x, z)} \\
&amp;= \mathcal L(\theta, \phi ; x)
\end{align}</div>
<script type="math/tex; mode=display">\begin{align}
\log p(x) &= \log \int p_\theta(x, z)dz \\
&= \log \int p_\theta(x, z) \frac{q_\phi(z | x)}{q_\phi(z | x)} dz \\
&= \log E_{z_\phi \sim q_\phi} \frac{p_\theta(x, z)}{q_\phi(z | x)} \\
\Rightarrow  \log E_{z_\phi \sim q_\phi} \frac{p_\theta(x, z)}{q_\phi(z | x)} & \ge E_{z_\phi \sim q_\phi} \log \frac{p_\theta(x, z)}{q_\phi(z | x)} \\  
&= - E_{z_\phi \sim q_\phi} \log \frac{q_\phi(z | x)}{p_\theta(x, z)} \\
&= \mathcal L(\theta, \phi ; x)
\end{align}</script>
</div>
<h3 id="alternative-forms-of-elbo-and-intuitions">Alternative Forms of ELBO and Intuitions<a class="headerlink" href="#alternative-forms-of-elbo-and-intuitions" title="Permanent link">&para;</a></h3>
<p>We have that</p>
<div>
<div class="MathJax_Preview">
\mathcal L(\theta, \phi ; x) = \text{ELBO} = - E_{z_\phi \sim q_\phi} \log \frac{q_\phi(z | x)}{p_\theta(x, z)}
</div>
<script type="math/tex; mode=display">
\mathcal L(\theta, \phi ; x) = \text{ELBO} = - E_{z_\phi \sim q_\phi} \log \frac{q_\phi(z | x)}{p_\theta(x, z)}
</script>
</div>
<p>1) The most general interpretation of the ELBO is given by</p>
<div>
<div class="MathJax_Preview">\begin{align}
  \mathcal L(\theta, \phi ; x) &amp;= - E_{z_\phi \sim q_\phi} \log \frac{q_\phi(z | x)}{p_\theta(x, z)} \\
  &amp;= E_{z_\phi \sim q_\phi} \log \frac{p_\theta(x, z)}{q_\phi(z | x)} \\
  &amp;= E_{z_\phi \sim q_\phi} \log \frac{p_\theta(z)p_\theta(x | z)}{q_\phi(z | x)} \\
  &amp;= E_{z_\phi \sim q_\phi} \Big [ \log p_\theta({x | z}) + \log p_\theta({z}) - \log {q_\phi(z | x)} \Big ]\\
\end{align}</div>
<script type="math/tex; mode=display">\begin{align}
  \mathcal L(\theta, \phi ; x) &= - E_{z_\phi \sim q_\phi} \log \frac{q_\phi(z | x)}{p_\theta(x, z)} \\
  &= E_{z_\phi \sim q_\phi} \log \frac{p_\theta(x, z)}{q_\phi(z | x)} \\
  &= E_{z_\phi \sim q_\phi} \log \frac{p_\theta(z)p_\theta(x | z)}{q_\phi(z | x)} \\
  &= E_{z_\phi \sim q_\phi} \Big [ \log p_\theta({x | z}) + \log p_\theta({z}) - \log {q_\phi(z | x)} \Big ]\\
\end{align}</script>
</div>
<p>2) We can also re-write 1) using entropy</p>
<div>
<div class="MathJax_Preview">
E_{z_\phi \sim q_\phi} \Big [ \log p_\theta({x | z}) + \log p_\theta({z}) \Big ] H \Big [ q_\phi(z | x) \Big ] \\
</div>
<script type="math/tex; mode=display">
E_{z_\phi \sim q_\phi} \Big [ \log p_\theta({x | z}) + \log p_\theta({z}) \Big ] H \Big [ q_\phi(z | x) \Big ] \\
</script>
</div>
<p>3) Another re-write and we arrive at</p>
<div>
<div class="MathJax_Preview">
E_{z_\phi \sim q_\phi} \Big [ \log p_\theta({x | z}) \Big ] - D_{KL}(q_\phi(z | x) || p_\theta(z))
</div>
<script type="math/tex; mode=display">
E_{z_\phi \sim q_\phi} \Big [ \log p_\theta({x | z}) \Big ] - D_{KL}(q_\phi(z | x) || p_\theta(z))
</script>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The instructor suggest that this would be useful for assignment 3.</p>
</div>
<p>This frames the ELBO as a tradeoff. The first term can be thought of as a "reconstruction likelihood", i.e. how probable is <span><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> given <span><span class="MathJax_Preview">z</span><script type="math/tex">z</script></span>, which encourages the model to choose the distribution which best reconstructs the data. The second term acts as regularization, by enforcing the idea that our parameterization shouldn't move us too far from the true distribution.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The instructor recommends we read "sticking the landing".</p>
</div>
<h3 id="mean-field-variational-inference">Mean Field Variational Inference<a class="headerlink" href="#mean-field-variational-inference" title="Permanent link">&para;</a></h3>
<p>In <a href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods#Mean_field_approximation">mean field variational inference</a>, the approximate distribution <span><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span> is assumed to factorize over some partition of latent variables</p>
<div>
<div class="MathJax_Preview">
q_\phi(z, \theta | \phi) = q_\phi(\theta | \phi_{\theta})\prod_{i=1}^Nq(z_i | \phi_i)
</div>
<script type="math/tex; mode=display">
q_\phi(z, \theta | \phi) = q_\phi(\theta | \phi_{\theta})\prod_{i=1}^Nq(z_i | \phi_i)
</script>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>I don't get this at all. The lecture had gotten pretty messy on the blackboard by this point.</p>
</div>
<p>If <span><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>s are in the same family as <span><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span>s, we can optimize via coordinate ascent.</p>
<p>we restrict ourselves to variational families, <span><span class="MathJax_Preview">q</span><script type="math/tex">q</script></span>, that we can compute the gradient of</p>
<h2 id="appendix">Appendix<a class="headerlink" href="#appendix" title="Permanent link">&para;</a></h2>
<h3 id="useful-resources">Useful Resources<a class="headerlink" href="#useful-resources" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://lingpipe-blog.com/2013/03/25/mean-field-variational-inference-made-easy/">High level overview</a> on variational inference.</li>
</ul>
<h3 id="glossary-of-terms">Glossary of Terms<a class="headerlink" href="#glossary-of-terms" title="Permanent link">&para;</a></h3>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../week_9/" title="Week 9" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Week 9
              </span>
            </div>
          </a>
        
        
          <a href="../week_11/" title="Week 11" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Week 11
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
  <div class="md-footer-social">
    <link rel="stylesheet" href="../../assets/fonts/font-awesome.css">
    
      <a href="https://github.com/JohnGiorgi" class="md-footer-social__link fa fa-github"></a>
    
  </div>

      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.b41f3d20.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"../.."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
    
      
    
  </body>
</html>